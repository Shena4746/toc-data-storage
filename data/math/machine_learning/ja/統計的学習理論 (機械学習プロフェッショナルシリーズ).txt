第1章 統計的学習理論の枠組 1
1.1 問題設定 1
1.1.1 判別問題 3
1.1.2 回帰問題 5
1.1.3 ランキング問題 5
1.2 予測損失と経験損失 7
1.3 ベイズ規則とベイズ誤差 9
1.4 学習アルゴリズムの性能評価 12
1.5 有限な仮説集合を用いた学習 14
1.5.1 予測判別誤差の評価 14
1.5.2 近似誤差と推定誤差 17
1.5.3 正則化 18
第2章 仮説集合の複雑度 20
2.1 VC次元 20
2.2 ラデマッハ複雑度 25
2.3 一様大数の法則 32
2.4 タラグランドの補題の証明 35
第3章 判別適合的損失 37
3.1 マージン損失 37
3.2 判別適合的損失 40
3.3 判別適合性定理: 凸マージン損失 45
3.4 判別適合性定理: 一般のマージン損失 49
第4章 カーネル法の基礎 54
4.1 線形モデルを用いた学習 54
4.2 カーネル関数 57
4.3 再生核ヒルベルト空間 60
4.3.1 カーネル関数から生成される内積空間 60
4.3.2 内積空間の完備化 61
4.3.3 再生核ヒルベルト空間とカーネル関数 64
4.3.4 ヒルベルト空間の分類と再生核ヒルベルト空間 67
4.4 表現定理 70
4.5 再生核ヒルベルト空間のラデマッハ複雑度 70
4.6 普遍カーネル 72
第5章 サポートベクトルマシン 79
5.1 導入 79
5.2 ヒンジ損失 80
5.3 C-サポートベクトルマシン 81
5.3.1 C-サポートベク トルマシンの最適性条件 82
5.3.2 サポートベクトル 84
5.3.3 サポートベクトル比と予測判別誤差 86
5.3.4 予測判別誤差の上界 88
5.3.5 統計的一致性 93
5.4 v-サポートベクトルマシン 97
5.4.1 v-サポートベク トルマシンの性質 98
5.4.2 双対表現と最小距離問題 101
5.4.3 予測判別誤差の評価と統計的一致性 104
第6章 ブースティング 110
6.1 集団学習 110
6.2 アダブースト 112
6.3 非線形最適化とブースティング 114
6.3.1 座標降下法によるブースティングの導出 114
6.3.2 重み付きデータによる学習と一般化線形モデル 117
6.4 アダブーストの誤差評価 120
6.4.1 経験判別誤差 120
6.4.2 予測判別誤差 122
第7章 多値判別 126
7.1 判別関数と判別器 126
7.2 ラデマッハ複雑度と予測判別誤差の評価 127
7.3 判別適合的損失 132
7.4 損失関数 135
7.4.1 多値マージン損失 135
7.4.2 判別適合的損失の例 137
7.5 統計的一致性 141
7.6 多値判別における判別適合性定理の証明 146
付録A 確率不等式 153
付録B 凸解析と凸最適化 158
B.1 凸集合 158
B.2 凸関数 161
B.3 凸最適化 165
付録C 関数解析の初歩 169
C.1 ルベーグ積分 169
C.2 ノルム空間・バナッハ空間 170
C.3 内積空間・ヒルベルト空間 171
■参考文献 177
■ 索引 179